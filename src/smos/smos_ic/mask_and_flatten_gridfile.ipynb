{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Beta version status - this Code was used to create land masked flat grid.nc for SMOS IC for v.105 ASC\n",
    "# it can be used as a blue print to create land masked grid file for future SMOS IC versions\n",
    "\n",
    "# CORRECT GRID CODE 1/2\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# 1. Open both datasets\n",
    "smos_data = xr.open_dataset('/path_to/grid_ic_Geo2D.nc') # produced when reshuffling image to ts\n",
    "mask_data = xr.open_dataset('/path_to/Grid_Point_Mask_USGS.nc') # can be found in src/smos\n",
    "\n",
    "# lat values in mask_data are flipped, so flip again!\n",
    "mask_data = mask_data.isel(lat=slice(None, None, -1))\n",
    "\n",
    "# 2. Interpolate the mask to match SMOS grid\n",
    "# This handles any floating point precision issues by creating a new mask on the exact SMOS grid\n",
    "regridded_mask = mask_data.interp(lat=smos_data.lat, lon=smos_data.lon, method='nearest')\n",
    "\n",
    "# 3. Get the land mask from the regridded data\n",
    "land_mask = regridded_mask['USGS_Land_Flag']\n",
    "\n",
    "# 4. Create a new dataset\n",
    "masked_ds = xr.Dataset()\n",
    "\n",
    "# 5. Copy variables while preserving original data types and units\n",
    "for var_name, var in smos_data.data_vars.items():\n",
    "    # Get the original data type\n",
    "    dtype = var.dtype\n",
    "\n",
    "    # Create masked variable\n",
    "    if 'lat' in var.dims and 'lon' in var.dims:  # 2D variables with lat/lon dimensions\n",
    "        if np.issubdtype(dtype, np.integer):\n",
    "            # For integer types, use a proper integer fill value\n",
    "            fill_value = -9999  # A conventional fill value for integers\n",
    "\n",
    "            # Create a masked array with the fill value\n",
    "            masked_data = xr.where(land_mask == 1, var, fill_value)\n",
    "\n",
    "            # Convert back to the original data type\n",
    "            masked_ds[var_name] = masked_data.astype(dtype)\n",
    "\n",
    "            # Copy all attributes except _FillValue (will handle in encoding)\n",
    "            attrs_copy = var.attrs.copy()\n",
    "            if '_FillValue' in attrs_copy:\n",
    "                del attrs_copy['_FillValue']  # Remove to avoid conflicts\n",
    "            masked_ds[var_name].attrs = attrs_copy\n",
    "        else:\n",
    "            # For float types, use NaN\n",
    "            masked_ds[var_name] = var.where(land_mask == 1)\n",
    "\n",
    "            # Copy all attributes except _FillValue (will handle in encoding)\n",
    "            attrs_copy = var.attrs.copy()\n",
    "            if '_FillValue' in attrs_copy:\n",
    "                del attrs_copy['_FillValue']  # Remove to avoid conflicts\n",
    "            masked_ds[var_name].attrs = attrs_copy\n",
    "    else:\n",
    "        # Copy other variables as-is\n",
    "        masked_ds[var_name] = var.copy()\n",
    "\n",
    "        # Copy all attributes except _FillValue (will handle in encoding)\n",
    "        attrs_copy = var.attrs.copy()\n",
    "        if '_FillValue' in attrs_copy:\n",
    "            del attrs_copy['_FillValue']  # Remove to avoid conflicts\n",
    "        masked_ds[var_name].attrs = attrs_copy\n",
    "\n",
    "# 6. Copy coordinates\n",
    "for coord_name, coord in smos_data.coords.items():\n",
    "    if coord_name not in masked_ds.coords:\n",
    "        masked_ds[coord_name] = coord.copy()\n",
    "\n",
    "        # Copy all attributes except _FillValue (will handle in encoding)\n",
    "        attrs_copy = coord.attrs.copy()\n",
    "        if '_FillValue' in attrs_copy:\n",
    "            del attrs_copy['_FillValue']  # Remove to avoid conflicts\n",
    "        masked_ds[coord_name].attrs = attrs_copy\n",
    "\n",
    "# Explicitly set critical lat/lon attributes (hardcoded)\n",
    "if 'lat' in masked_ds.coords:\n",
    "    masked_ds['lat'].attrs['long_name'] = \"Latitude\"\n",
    "    masked_ds['lat'].attrs['units'] = \"degree_north\"\n",
    "    masked_ds['lat'].attrs['standard_name'] = \"latitude\"\n",
    "\n",
    "if 'lon' in masked_ds.coords:\n",
    "    masked_ds['lon'].attrs['long_name'] = \"Longitude\"\n",
    "    masked_ds['lon'].attrs['units'] = \"degree_east\"\n",
    "    masked_ds['lon'].attrs['standard_name'] = \"longitude\"\n",
    "\n",
    "# 7. Copy attributes\n",
    "masked_ds.attrs.update(smos_data.attrs)\n",
    "masked_ds.attrs['masking_applied'] = 'USGS_Land_Flag from Grid_Point_Mask_USGS.nc (interpolated to match grid)'\n",
    "masked_ds.attrs['masking_description'] = 'Only land grid points (USGS_Land_Flag=1) are included'\n",
    "masked_ds.attrs['interpolation_method'] = 'Nearest-neighbor interpolation used to regrid mask to SMOS coordinates'\n",
    "\n",
    "# 8. Check data types and units before saving\n",
    "print(\"Variable data types and units before saving:\")\n",
    "for var_name in masked_ds.data_vars:\n",
    "    unit_info = f\"units: {masked_ds[var_name].attrs.get('units', 'Not specified')}\" if 'units' in masked_ds[var_name].attrs else \"No units attribute\"\n",
    "    print(f\"{var_name}: {masked_ds[var_name].dtype}, {unit_info}\")\n",
    "\n",
    "# 9. Save with compression\n",
    "# Create encoding dict with compression and explicit dtypes\n",
    "encoding = {}\n",
    "for var in masked_ds.data_vars:\n",
    "    encoding[var] = {\n",
    "        'zlib': True, \n",
    "        'complevel': 4,\n",
    "        'dtype': masked_ds[var].dtype  # Explicitly set dtype to preserve it\n",
    "    }\n",
    "\n",
    "    # For integer types that we masked, set the fill value in encoding\n",
    "    if np.issubdtype(masked_ds[var].dtype, np.integer) and 'lat' in masked_ds[var].dims and 'lon' in masked_ds[var].dims:\n",
    "        encoding[var]['_FillValue'] = -9999\n",
    "\n",
    "# Also handle coordinates encoding\n",
    "for coord in masked_ds.coords:\n",
    "    encoding[coord] = {\n",
    "        'dtype': masked_ds[coord].dtype,\n",
    "        'zlib': True,\n",
    "        'complevel': 4\n",
    "    }\n",
    "\n",
    "masked_ds.to_netcdf('./smos_ic_land_Geo2D.nc',\n",
    "                   encoding=encoding)\n",
    "\n",
    "# 10. Statistics\n",
    "total_points = land_mask.size\n",
    "land_points = (land_mask == 1).sum().item()\n",
    "percentage_land = (land_points / total_points) * 100\n",
    "\n",
    "print(\"Successfully created land-masked NetCDF file: smos_ic_land_Geo2D.nc\")\n",
    "print(f\"Total grid points: {total_points}\")\n",
    "print(f\"Land points (USGS_Land_Flag=1): {land_points}\")\n",
    "print(f\"Percentage of land points: {percentage_land:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CORRECT GRID CODE 2/2 - flatten it!!\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Open the 2D NetCDF file\n",
    "ds = xr.open_dataset('/path_to/smos_ic_land_Geo2D.nc')\n",
    "\n",
    "# Extract 2D arrays\n",
    "lat_2d = ds.lat.values\n",
    "lon_2d = ds.lon.values\n",
    "gpi_2d = ds.gpi.values\n",
    "cell_2d = ds.cell.values\n",
    "\n",
    "# Create meshgrid of lat/lon values\n",
    "lon_mesh, lat_mesh = np.meshgrid(lon_2d, lat_2d)\n",
    "\n",
    "# Find valid grid points (where both gpi and cell are not -9999 and not NaN)\n",
    "gpi_valid = (gpi_2d != -9999) & (~np.isnan(gpi_2d))\n",
    "cell_valid = (cell_2d != -9999) & (~np.isnan(cell_2d))\n",
    "valid_mask = gpi_valid & cell_valid\n",
    "\n",
    "# Check overlap between gpi and cell valid/invalid points\n",
    "gpi_invalid = ~gpi_valid\n",
    "cell_invalid = ~cell_valid\n",
    "overlap_invalid = np.logical_and(gpi_invalid, cell_invalid)\n",
    "overlap_percentage = np.sum(overlap_invalid) / np.sum(gpi_invalid) * 100\n",
    "print(f\"Invalid value overlap: {overlap_percentage:.2f}%\")\n",
    "\n",
    "# Count points where only one is invalid but not the other\n",
    "gpi_only_invalid = np.logical_and(gpi_invalid, ~cell_invalid)\n",
    "cell_only_invalid = np.logical_and(~gpi_invalid, cell_invalid)\n",
    "print(f\"Points where only GPI is invalid: {np.sum(gpi_only_invalid)}\")\n",
    "print(f\"Points where only CELL is invalid: {np.sum(cell_only_invalid)}\")\n",
    "\n",
    "# Extract 1D arrays for valid points only\n",
    "lat_1d = lat_mesh[valid_mask]\n",
    "lon_1d = lon_mesh[valid_mask]\n",
    "gpi_1d = gpi_2d[valid_mask]\n",
    "cell_1d = cell_2d[valid_mask]\n",
    "\n",
    "# Convert gpi and cell to integers\n",
    "gpi_1d = gpi_1d.astype(np.int32)\n",
    "cell_1d = cell_1d.astype(np.int32)\n",
    "\n",
    "# Count valid grid points\n",
    "num_valid_points = len(lat_1d)\n",
    "print(f\"Number of valid grid points: {num_valid_points}\")\n",
    "print(f\"Original number of grid points: {np.prod(gpi_2d.shape)}\")\n",
    "print(f\"Percentage of valid points: {(num_valid_points / np.prod(gpi_2d.shape)) * 100:.2f}%\")\n",
    "\n",
    "# Create new 1D dataset with 'gp' as a dimension only, not a coordinate\n",
    "ds_1d = xr.Dataset(\n",
    "    data_vars={\n",
    "        'lat': (['gp'], lat_1d),\n",
    "        'lon': (['gp'], lon_1d),\n",
    "        'gpi': (['gp'], gpi_1d),\n",
    "        'cell': (['gp'], cell_1d),\n",
    "        'crs': ds.crs\n",
    "    }\n",
    ")\n",
    "\n",
    "# Copy variable attributes from original dataset\n",
    "ds_1d.lat.attrs = ds.lat.attrs.copy()\n",
    "ds_1d.lon.attrs = ds.lon.attrs.copy()\n",
    "ds_1d.gpi.attrs = ds.gpi.attrs.copy()\n",
    "ds_1d.cell.attrs = ds.cell.attrs.copy()\n",
    "ds_1d.crs.attrs = ds.crs.attrs.copy()\n",
    "\n",
    "# Update attributes for 1D format\n",
    "ds_1d.lat.attrs.pop('_ChunkSizes', None)\n",
    "ds_1d.lon.attrs.pop('_ChunkSizes', None)\n",
    "ds_1d.lat.attrs['valid_range'] = [-90.0, 90.0]\n",
    "ds_1d.lon.attrs['valid_range'] = [-180.0, 180.0]\n",
    "\n",
    "# Update chunking for 1D arrays\n",
    "ds_1d.lat.attrs['_ChunkSizes'] = num_valid_points\n",
    "ds_1d.lon.attrs['_ChunkSizes'] = num_valid_points\n",
    "ds_1d.gpi.attrs['_ChunkSizes'] = num_valid_points\n",
    "ds_1d.cell.attrs['_ChunkSizes'] = num_valid_points\n",
    "\n",
    "# Copy all global attributes from the original dataset\n",
    "for attr_name, attr_value in ds.attrs.items():\n",
    "    ds_1d.attrs[attr_name] = attr_value\n",
    "\n",
    "# Update the shape global attribute to be a long integer instead of a string\n",
    "ds_1d.attrs['shape'] = np.int64(num_valid_points)  # Set as a long integer\n",
    "\n",
    "\n",
    "\n",
    "# Save the new 1D NetCDF file\n",
    "output_path = '/output_path/smos_ic_land_flat.nc'\n",
    "encoding = {\n",
    "    'lat': {'zlib': True, 'complevel': 4},\n",
    "    'lon': {'zlib': True, 'complevel': 4},\n",
    "    'gpi': {'zlib': True, 'complevel': 4, 'dtype': 'int32'},\n",
    "    'cell': {'zlib': True, 'complevel': 4, 'dtype': 'int32'},\n",
    "    'crs': {'zlib': True, 'complevel': 4}\n",
    "}\n",
    "ds_1d.to_netcdf(output_path, encoding=encoding)\n",
    "\n",
    "print(f\"1D grid file saved to: {output_path}\")\n",
    "print(f\"Global attributes set with shape as long integer: {ds_1d.attrs.get('shape')} (type: {type(ds_1d.attrs.get('shape'))})\")\n",
    "print(f\"Dimensions: {list(ds_1d.dims)}\")\n",
    "print(f\"Coordinates: {list(ds_1d.coords)}\")\n",
    "print(f\"GPI data type: {ds_1d.gpi.dtype}\")\n",
    "print(f\"CELL data type: {ds_1d.cell.dtype}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
